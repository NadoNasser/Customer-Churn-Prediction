{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['models/model_columns.pkl']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# download data\n",
        "df = pd.read_csv('C:/Users/hp/projects/Churn_Prediction_Project/data/telecome_churn.csv')\n",
        "\n",
        "# clean 'TotalCharges' column\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# preparation\n",
        "X = df.drop(\"Churn\", axis=1)\n",
        "y = df[\"Churn\"].map({'Yes': 1, 'No': 0})\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Ø­ÙØ¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "joblib.dump(X.columns, \"models/model_columns.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['models/scaler.pkl']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "joblib.dump(scaler, \"models/scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:28:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'RandomForest' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:28:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForest, version 4\n",
            "Created version '4' of model 'RandomForest'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: RandomForest\n",
            "Test Accuracy: 95.458%\n",
            "\n",
            "ðŸƒ View run RandomForest at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/2851142957f74a8cab3de24cff396fae\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:29:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'GradientBoosting' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:29:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: GradientBoosting, version 4\n",
            "Created version '4' of model 'GradientBoosting'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: GradientBoosting\n",
            "Test Accuracy: 95.458%\n",
            "\n",
            "ðŸƒ View run GradientBoosting at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/1fd89f95247c47b5b2309c0965636b97\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:29:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'SVM' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:29:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: SVM, version 4\n",
            "Created version '4' of model 'SVM'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: SVM\n",
            "Test Accuracy: 93.573%\n",
            "\n",
            "ðŸƒ View run SVM at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/abd48bbd7fe3407487a5eaf166c8117d\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:29:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'LogisticRegression' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:29:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LogisticRegression, version 4\n",
            "Created version '4' of model 'LogisticRegression'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: LogisticRegression\n",
            "Test Accuracy: 91.774%\n",
            "\n",
            "ðŸƒ View run LogisticRegression at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/3a44e5af488748c9a06b557c8681f8a2\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:30:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'DecisionTree' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:30:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: DecisionTree, version 4\n",
            "Created version '4' of model 'DecisionTree'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: DecisionTree\n",
            "Test Accuracy: 93.059%\n",
            "\n",
            "ðŸƒ View run DecisionTree at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/e76a67a92e0a41208711d52e80cebd14\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:30:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'AdaBoost' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:30:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: AdaBoost, version 4\n",
            "Created version '4' of model 'AdaBoost'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: AdaBoost\n",
            "Test Accuracy: 94.602%\n",
            "\n",
            "ðŸƒ View run AdaBoost at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/65064db4851f4ae988f7e701ba3a7d42\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:32:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'XGBoost' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:32:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoost, version 7\n",
            "Created version '7' of model 'XGBoost'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: XGBoost\n",
            "Test Accuracy: 95.887%\n",
            "\n",
            "ðŸƒ View run XGBoost at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/d961dcc7992845a2b64371bb38dcae16\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/09 12:32:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Registered model 'NaiveBayes' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:32:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: NaiveBayes, version 4\n",
            "Created version '4' of model 'NaiveBayes'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: NaiveBayes\n",
            "Test Accuracy: 88.260%\n",
            "\n",
            "ðŸƒ View run NaiveBayes at: http://127.0.0.1:5000/#/experiments/206707251724781243/runs/d14ca02cd95c4220a64b781ff606169e\n",
            "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/206707251724781243\n",
            "Best Model:\n",
            "Model Name: XGBoost\n",
            "Test Accuracy: 95.887%\n",
            "Model Pipeline: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
            "                ('model',\n",
            "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "                               colsample_bylevel=None, colsample_bynode=None,\n",
            "                               colsample_bytree=None, device=None,\n",
            "                               early_stopping_rounds=None,\n",
            "                               enable_categorical=False, eval_metric='logloss',\n",
            "                               feature_types=None, feature_weights=None,\n",
            "                               gamma=None, grow_policy=None,\n",
            "                               importance_type=None,\n",
            "                               interaction_constraints=None,\n",
            "                               learning_rate=np.float64(0.08951440421750446),\n",
            "                               max_bin=None, max_cat_threshold=None,\n",
            "                               max_cat_to_onehot=None, max_delta_step=None,\n",
            "                               max_depth=5, max_leaves=None,\n",
            "                               min_child_weight=None, missing=nan,\n",
            "                               monotone_constraints=None, multi_strategy=None,\n",
            "                               n_estimators=181, n_jobs=None,\n",
            "                               num_parallel_tree=None, ...))])\n",
            "Accuracy: 95.89%\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.combine import SMOTEENN\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "\n",
        "# Step 1: Load and preprocess the data\n",
        "# Load the dataset\n",
        "df = pd.read_csv('C:/Users/hp/projects/Churn_Prediction_Project/data/telecome_churn.csv')\n",
        "\n",
        "# Handle missing values and data types\n",
        "# Convert 'TotalCharges' to numeric, replacing empty strings with 0\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce').fillna(0)\n",
        "\n",
        "\n",
        "df = df.drop(columns=['customerID'])\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "# Identify categorical and numerical columns for preprocessing\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a preprocessing pipeline for categorical and numerical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numerical_cols),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Apply preprocessing\n",
        "X = preprocessor.fit_transform(X)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "joblib.dump(preprocessor, 'models/preprocessor.pkl')\n",
        "# Convert back to DataFrame for consistency\n",
        "X = pd.DataFrame(X, columns=numerical_cols.tolist() + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)))\n",
        "\n",
        "# UpSampling with SMOTEENN, ensuring random_state is set\n",
        "sm = SMOTEENN(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "#  Split the data with a fixed random_state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and their hyperparameter grids \n",
        "models = [\n",
        "    ('RandomForest', RandomForestClassifier(random_state=42),\n",
        "        {'model__n_estimators': [50, 100, 200],\n",
        "         'model__max_depth': [None, 10, 20]}),\n",
        "    ('GradientBoosting', GradientBoostingClassifier(random_state=42),\n",
        "        {'model__n_estimators': [50, 100, 200],\n",
        "         'model__learning_rate': [0.05, 0.1, 0.5]}),\n",
        "    ('SVM', SVC(random_state=42, class_weight='balanced', probability=True),\n",
        "        {'model__C': [0.1, 1, 10],\n",
        "         'model__gamma': ['scale', 'auto']}),\n",
        "    ('LogisticRegression', LogisticRegression(random_state=42, class_weight='balanced'),\n",
        "        {'model__C': [0.1, 1, 10],\n",
        "         'model__penalty': ['l1', 'l2']}),\n",
        "    ('DecisionTree', DecisionTreeClassifier(random_state=42),\n",
        "        {'model__max_depth': [None, 10, 20],\n",
        "         'model__min_samples_split': [2, 5, 10]}),\n",
        "    ('AdaBoost', AdaBoostClassifier(random_state=42),\n",
        "        {'model__n_estimators': [50, 100, 200],\n",
        "         'model__learning_rate': [0.05, 0.1, 0.5]}),\n",
        "    ('XGBoost', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
        "        {'model__max_depth': randint(3, 6),\n",
        "         'model__learning_rate': uniform(0.01, 0.2),\n",
        "         'model__n_estimators': randint(100, 300),\n",
        "         'model__subsample': uniform(0.8, 0.2)}),\n",
        "    ('NaiveBayes', GaussianNB(), {})  # No hyperparameters for Naive Bayes\n",
        "]\n",
        "\n",
        "# Set up MLflow\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "mlflow.set_experiment(\"Churn Prediction\")\n",
        "\n",
        "# Define the training and logging function\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "best_model_name = None\n",
        "model_scores = []  \n",
        "\n",
        "def train_and_log_model(name, model, param_grid, X_train, X_test, y_train, y_test):\n",
        "    global best_model, best_accuracy, best_model_name\n",
        "    \n",
        "    with mlflow.start_run(run_name=name) as run:\n",
        "        # Create a pipeline with scaler and model\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', MinMaxScaler()),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Hyperparameter tuning\n",
        "        if name == 'XGBoost':\n",
        "            random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid,\n",
        "                                               n_iter=100, cv=3, verbose=0, random_state=42, n_jobs=-1)\n",
        "            random_search.fit(X_train, y_train)\n",
        "            best_pipeline = random_search.best_estimator_\n",
        "        elif param_grid:\n",
        "            grid_search = GridSearchCV(pipeline, param_grid, cv=2, verbose=0)\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            best_pipeline = grid_search.best_estimator_\n",
        "        else:\n",
        "            best_pipeline = pipeline\n",
        "            best_pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        preds = best_pipeline.predict(X_test)\n",
        "        probs = best_pipeline.predict_proba(X_test)[:, 1] if hasattr(best_pipeline, \"predict_proba\") else None\n",
        "\n",
        "        # Calculate metrics\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        prec = precision_score(y_test, preds)\n",
        "        rec = recall_score(y_test, preds)\n",
        "        f1 = f1_score(y_test, preds)\n",
        "        roc_auc = roc_auc_score(y_test, probs) if probs is not None else None\n",
        "\n",
        "        # Log parameters and metrics to MLflow\n",
        "        mlflow.log_param(\"model_name\", name)\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision\", prec)\n",
        "        mlflow.log_metric(\"recall\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n",
        "        if roc_auc is not None:\n",
        "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(best_pipeline, artifact_path=\"model\")\n",
        "        model_uri = f\"runs:/{run.info.run_id}/model\"\n",
        "        mlflow.register_model(model_uri=model_uri, name=name)\n",
        "\n",
        "        # Save the model locally\n",
        "        joblib.dump(best_pipeline, f\"models/{name}_model.pkl\")\n",
        "\n",
        "        # Store the scores\n",
        "        model_scores.append({'Model': name, 'Accuracy': acc})\n",
        "\n",
        "        # Print performance metrics in a format similar to the first code\n",
        "        print(f\"Model: {name}\")\n",
        "        print(f\"Test Accuracy: {acc*100:.3f}%\")\n",
        "        print()\n",
        "\n",
        "        # Check if the current model has the best accuracy\n",
        "        if acc > best_accuracy:\n",
        "            best_accuracy = acc\n",
        "            best_model = best_pipeline\n",
        "            best_model_name = name\n",
        "\n",
        "# Train and log all models\n",
        "for name, model, param_grid in models:\n",
        "    train_and_log_model(name, model, param_grid, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the best model \n",
        "print(\"Best Model:\")\n",
        "print(f\"Model Name: {best_model_name}\")\n",
        "print(f\"Test Accuracy: {best_accuracy*100:.3f}%\")\n",
        "print(f\"Model Pipeline: {best_model}\")\n",
        "print(f\"Accuracy: {best_accuracy:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model XGBoost version 7 promoted to Production\n"
          ]
        }
      ],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "client = MlflowClient()\n",
        "\n",
        "model_name = best_model_name \n",
        "latest_version = max([model.version for model in client.search_model_versions(f\"name='{model_name}'\")])\n",
        "\n",
        "# \"Production\"\n",
        "client.transition_model_version_stage(\n",
        "    name=model_name,\n",
        "    version=latest_version,\n",
        "    stage=\"Production\"\n",
        ")\n",
        "\n",
        "print(f\"Model {model_name} version {latest_version} promoted to Production\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'XGBoost' already exists. Creating a new version of this model...\n",
            "2025/05/09 12:35:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoost, version 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Best model 'XGBoost' registered as version 8 and moved to Production.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created version '8' of model 'XGBoost'.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Get the best run from the experiment sorted by F1 score\n",
        "client = MlflowClient()\n",
        "experiment = mlflow.get_experiment_by_name(\"Churn Prediction\")\n",
        "runs = client.search_runs(experiment.experiment_id, order_by=[\"metrics.f1_score DESC\"])\n",
        "\n",
        "# Pick the best run\n",
        "best_run = runs[0]\n",
        "best_model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
        "best_model_name = best_run.data.params[\"model_name\"]\n",
        "\n",
        "# Register the best model\n",
        "result = mlflow.register_model(model_uri=best_model_uri, name=best_model_name)\n",
        "\n",
        "# Transition the model version to 'Production'\n",
        "client.transition_model_version_stage(\n",
        "    name=best_model_name,\n",
        "    version=result.version,\n",
        "    stage=\"Production\"\n",
        ")\n",
        "\n",
        "print(f\"âœ… Best model '{best_model_name}' registered as version {result.version} and moved to Production.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.00it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: ['Yes', 'No', 'Yes', 'No', 'No']\n",
            "   gender  tenure  MonthlyCharges  TotalCharges Predicted_Churn\n",
            "0  Female       1           29.85         29.85             Yes\n",
            "1    Male      34           56.95       1889.50              No\n",
            "2    Male       2           53.85        108.15             Yes\n",
            "3  Female      45           80.00       3650.00              No\n",
            "4    Male       5           25.70        128.35              No\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from mlflow.sklearn import load_model\n",
        "\n",
        "# 1. Load new data\n",
        "df_new = pd.read_csv(\"C:/Users/hp/projects/Churn_Prediction_Project/data/new_customers.csv\")\n",
        "\n",
        "# 2. Drop 'customerID' if it exists\n",
        "if 'customerID' in df_new.columns:\n",
        "    df_new = df_new.drop(columns=['customerID']) \n",
        "\n",
        "# 3. Clean 'TotalCharges'\n",
        "if 'TotalCharges' in df_new.columns:\n",
        "    df_new['TotalCharges'] = pd.to_numeric(df_new['TotalCharges'], errors='coerce')\n",
        "df_new = df_new.dropna()\n",
        "\n",
        "# 4. Load the preprocessor (used during training)\n",
        "preprocessor = joblib.load(\"C:/Users/hp/projects/Churn_Prediction_Project/src/models/preprocessor.pkl\")\n",
        "\n",
        "# 5. Transform the new data using the same preprocessor\n",
        "X_new = preprocessor.transform(df_new)\n",
        "\n",
        "# 6. Load the registered model\n",
        "model = load_model(\"models:/XGBoost/Production\")\n",
        "\n",
        "# 7. Predict\n",
        "predictions = model.predict(X_new)\n",
        "predictions = ['Yes' if p==1 else 'No' for p in predictions]\n",
        "print(\"Predictions:\", predictions)\n",
        "\n",
        "df_new['Predicted_Churn'] = predictions\n",
        "\n",
        "print(df_new[['gender','tenure','MonthlyCharges','TotalCharges','Predicted_Churn']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitoring and Alerts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'evidently'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import necessary libraries for monitoring and alerts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolumn_mapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnMapping\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Report\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetric_preset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataDriftPreset, TargetDriftPreset\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'evidently'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries for monitoring and alerts\n",
        "from evidently.pipeline.column_mapping import ColumnMapping\n",
        "from evidently.report import Report\n",
        "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import mlflow\n",
        "\n",
        "# Email settings for alerts\n",
        "SMTP_SERVER = \"smtp.gmail.com\"  # SMTP server for Gmail\n",
        "SMTP_PORT = 587  # Port for TLS\n",
        "EMAIL_ADDRESS = \"your_email@gmail.com\"  # Replace with your email\n",
        "EMAIL_PASSWORD = \"your_app_password\"  # Replace with your App Password\n",
        "ALERT_RECIPIENT = \"recipient_email@example.com\"  # Replace with recipient email\n",
        "\n",
        "# Function to send email alerts\n",
        "def send_alert(subject, body):\n",
        "    # Create a multipart email message\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = EMAIL_ADDRESS\n",
        "    msg['To'] = ALERT_RECIPIENT\n",
        "    msg['Subject'] = subject\n",
        "    msg.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "    # Send the email using SMTP\n",
        "    with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n",
        "        server.starttls()\n",
        "        server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
        "        server.sendmail(EMAIL_ADDRESS, ALERT_RECIPIENT, msg.as_string())\n",
        "        print(f\"Alert sent to {ALERT_RECIPIENT}\")\n",
        "\n",
        "# Load reference and current data for monitoring\n",
        "def load_data():\n",
        "    # Load reference data (training dataset)\n",
        "    reference_data = pd.read_csv('C:/Users/hp/projects/Churn_Prediction_Project/data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "    reference_data['TotalCharges'] = pd.to_numeric(reference_data['TotalCharges'], errors='coerce').fillna(0)\n",
        "    reference_data = reference_data.drop(columns=['customerID'])\n",
        "    reference_data['Churn'] = reference_data['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    # Load current data (new data for prediction)\n",
        "    current_data = pd.read_csv('C:/Users/hp/projects/Churn_Prediction_Project/data/new_customers.csv')\n",
        "    if 'customerID' in current_data.columns:\n",
        "        current_data = current_data.drop(columns=['customerID'])\n",
        "    if 'TotalCharges' in current_data.columns:\n",
        "        current_data['TotalCharges'] = pd.to_numeric(current_data['TotalCharges'], errors='coerce')\n",
        "    current_data = current_data.dropna()\n",
        "\n",
        "    return reference_data, current_data\n",
        "\n",
        "# Load model and preprocessor\n",
        "def load_model_and_preprocessor(model_name=\"XGBoost\"):\n",
        "    # Load the preprocessor\n",
        "    preprocessor = joblib.load('C:/Users/hp/projects/Churn_Prediction_Project/src/models/preprocessor.pkl')\n",
        "    # Load the model based on the model name\n",
        "    model = joblib.load(f'C:/Users/hp/projects/Churn_Prediction_Project/src/models/{model_name}_model.pkl')\n",
        "    return model, preprocessor\n",
        "\n",
        "# Monitor model performance and detect drift\n",
        "def monitor_model_performance(model_name=\"XGBoost\"):\n",
        "    # Load data for monitoring\n",
        "    reference_data, current_data = load_data()\n",
        "\n",
        "    # Separate features and target\n",
        "    X_ref = reference_data.drop(columns=['Churn'])\n",
        "    y_ref = reference_data['Churn']\n",
        "    X_cur = current_data\n",
        "\n",
        "    # Load model and preprocessor\n",
        "    model, preprocessor = load_model_and_preprocessor(model_name)\n",
        "\n",
        "    # Transform data using the preprocessor\n",
        "    X_ref_transformed = preprocessor.transform(X_ref)\n",
        "    X_cur_transformed = preprocessor.transform(X_cur)\n",
        "\n",
        "    # Make predictions on reference data\n",
        "    y_ref_pred = model.predict(X_ref_transformed)\n",
        "    y_ref_proba = model.predict_proba(X_ref_transformed)[:, 1]\n",
        "\n",
        "    # Add predictions to datasets\n",
        "    reference_data['prediction'] = y_ref_pred\n",
        "    current_data['prediction'] = model.predict(X_cur_transformed)\n",
        "\n",
        "    # Set up column mapping for Evidently\n",
        "    column_mapping = ColumnMapping()\n",
        "    column_mapping.target = 'Churn'\n",
        "    column_mapping.prediction = 'prediction'\n",
        "    column_mapping.numerical_features = X_ref.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    column_mapping.categorical_features = X_ref.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Generate drift report using Evidently\n",
        "    drift_report = Report(metrics=[\n",
        "        DataDriftPreset(),\n",
        "        TargetDriftPreset()\n",
        "    ])\n",
        "    drift_report.run(reference_data=reference_data, current_data=current_data, column_mapping=column_mapping)\n",
        "\n",
        "    # Save the drift report as HTML\n",
        "    os.makedirs('reports', exist_ok=True)\n",
        "    drift_report.save_html('reports/drift_report.html')\n",
        "\n",
        "    # Extract drift detection results\n",
        "    drift_detected = drift_report.as_dict()['metrics'][0]['result']['dataset_drift']  # Data Drift\n",
        "    target_drift_detected = drift_report.as_dict()['metrics'][1]['result']['drift_detected']  # Target Drift\n",
        "\n",
        "    # Log metrics to MLflow\n",
        "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "    mlflow.set_experiment(\"Churn Prediction Monitoring\")\n",
        "    with mlflow.start_run(run_name=f\"Monitoring_{model_name}\"):\n",
        "        mlflow.log_artifact('reports/drift_report.html')\n",
        "\n",
        "    # Send alert if drift is detected\n",
        "    if drift_detected or target_drift_detected:\n",
        "        subject = \"Warning: Model Drift Detected\"\n",
        "        body = f\"\"\"\n",
        "        Drift detected in model {model_name} performance.\n",
        "        - Data Drift: {drift_detected}\n",
        "        - Target Drift: {target_drift_detected}\n",
        "        Check the drift report at reports/drift_report.html\n",
        "        \"\"\"\n",
        "        send_alert(subject, body)\n",
        "\n",
        "    print(f\"Drift report generated at reports/drift_report.html\")\n",
        "    print(f\"Data Drift Detected: {drift_detected}\")\n",
        "    print(f\"Target Drift Detected: {target_drift_detected}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the monitoring for the best model\n",
        "    monitor_model_performance(model_name=\"XGBoost\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
